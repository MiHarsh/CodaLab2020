{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conventional_Approaches.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiHarsh/CodaLab-SharedTask/blob/main/Conventional_Approaches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dPZIt07-klz"
      },
      "source": [
        "Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ChXEyRF7x4f",
        "outputId": "7ae82d5f-92cd-468e-d330-4f3398c21022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-2b199d99-d0f1-fa56-c08c-dfe7c9ae4413)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W82elW6H5swu",
        "outputId": "4412462b-a3eb-43b6-f3c5-fbbf8db78bcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "import sys\n",
        "import re\n",
        "!pip install emoji --quiet\n",
        "import emoji\n",
        "!pip install contractions --quiet\n",
        "import contractions\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import unicodedata"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██████▍                         | 10kB 30.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 40kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 245kB 5.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 317kB 12.4MB/s \n",
            "\u001b[?25h  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pprVPNLz-uwK"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntfyXmtW5ybP",
        "outputId": "01ed0c7f-488b-4ad1-ed85-4758dac9ca7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_datapath=\"https://raw.githubusercontent.com/MiHarsh/MiHarsh/master/Constraint_English_Train%20-%20Sheet1.csv\"\n",
        "val_datapath  =\"https://raw.githubusercontent.com/MiHarsh/MiHarsh/master/Constraint_English_Val%20-%20Sheet1.csv\"\n",
        "train         = pd.read_csv(train_datapath)\n",
        "valid         = pd.read_csv(val_datapath)\n",
        "total         = pd.concat([train,valid],ignore_index=True)\n",
        "mix           = total.iloc[:,1:]\n",
        "mix"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8555</th>\n",
              "      <td>Donald Trump wrongly claimed that New Zealand ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8556</th>\n",
              "      <td>Current understanding is #COVID19 spreads most...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8557</th>\n",
              "      <td>Nothing screams “I am sat around doing fuck al...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8558</th>\n",
              "      <td>Birx says COVID-19 outbreak not under control ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8559</th>\n",
              "      <td>Another 4422 new coronavirus cases have been c...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8560 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweet label\n",
              "0     The CDC currently reports 99031 deaths. In gen...  real\n",
              "1     States reported 1121 deaths a small rise from ...  real\n",
              "2     Politically Correct Woman (Almost) Uses Pandem...  fake\n",
              "3     #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
              "4     Populous states can generate large case counts...  real\n",
              "...                                                 ...   ...\n",
              "8555  Donald Trump wrongly claimed that New Zealand ...  fake\n",
              "8556  Current understanding is #COVID19 spreads most...  real\n",
              "8557  Nothing screams “I am sat around doing fuck al...  fake\n",
              "8558  Birx says COVID-19 outbreak not under control ...  fake\n",
              "8559  Another 4422 new coronavirus cases have been c...  real\n",
              "\n",
              "[8560 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UkHQmWZ-xa5"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ-EDDek5-VP",
        "outputId": "d67b6d2e-bf34-43b0-9783-6ed4f6f62288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "def cleaning(text):\n",
        "  text= text.lower()\n",
        "  text= emoji.demojize(text)\n",
        "  text=contractions.fix(text)\n",
        "  text=text.strip()\n",
        "  text=text.replace('[^\\w\\s]','')\n",
        "  text=re.sub(r'http\\S+', '', text)\n",
        "  REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "  BAD_SYMBOLS_RE = re.compile('[^0-9a-z +]')\n",
        "  text = REPLACE_BY_SPACE_RE.sub(' ' , text)\n",
        "  text = BAD_SYMBOLS_RE.sub(' ',text)\n",
        "  \n",
        "  return text\n",
        "\n",
        "clean=mix['tweet'].apply(cleaning)\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "ff=[]\n",
        "for i in clean:\n",
        "  text=unicodedata.normalize('NFKD', i).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "  ff.append(text)\n",
        "dd=pd.DataFrame(ff)\n",
        "dataset = pd.concat([dd,mix['label']],axis=1)\n",
        "dataset"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the cdc currently reports 99031 deaths  in gen...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>states reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>politically correct woman  almost  uses pandem...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>indiafightscorona  we have 1524  covid testin...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8555</th>\n",
              "      <td>donald trump wrongly claimed that new zealand ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8556</th>\n",
              "      <td>current understanding is  covid19 spreads most...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8557</th>\n",
              "      <td>nothing screams  i am sat around doing fuck al...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8558</th>\n",
              "      <td>birx says covid 19 outbreak not under control ...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8559</th>\n",
              "      <td>another 4422 new coronavirus cases have been c...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8560 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      0 label\n",
              "0     the cdc currently reports 99031 deaths  in gen...  real\n",
              "1     states reported 1121 deaths a small rise from ...  real\n",
              "2     politically correct woman  almost  uses pandem...  fake\n",
              "3      indiafightscorona  we have 1524  covid testin...  real\n",
              "4     populous states can generate large case counts...  real\n",
              "...                                                 ...   ...\n",
              "8555  donald trump wrongly claimed that new zealand ...  fake\n",
              "8556  current understanding is  covid19 spreads most...  real\n",
              "8557  nothing screams  i am sat around doing fuck al...  fake\n",
              "8558  birx says covid 19 outbreak not under control ...  fake\n",
              "8559  another 4422 new coronavirus cases have been c...  real\n",
              "\n",
              "[8560 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJJ56wPV-2ZK"
      },
      "source": [
        "## Models for Conventional Approaches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb_0JAnh77fp"
      },
      "source": [
        "regressor = LogisticRegression(solver='liblinear') \n",
        "S         = svm.SVC()\n",
        "N         = BernoulliNB()\n",
        "Rf        = RandomForestClassifier(max_depth=8, random_state=0)\n",
        "ANN       = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                   hidden_layer_sizes=(5, 2), random_state=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u-GT3S67OwC"
      },
      "source": [
        "## Count Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gof0Saa6ouv",
        "outputId": "755a6344-797c-4a3b-ea06-498f496792d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cv= CountVectorizer()\n",
        "transform = cv.fit_transform(dataset[0].values.astype('U'))\n",
        "x_train= transform[:len(train)]                                           #trainset \n",
        "x_valid= transform[len(train):]                                           #validset\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6420, 16488)\n",
            "(2140, 16488)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TInsrnfBAZjl"
      },
      "source": [
        "### Training the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9ROXHwc9A17",
        "outputId": "adeafa09-26d4-467a-a190-83e433f203b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "regressor.fit(x_train,dataset['label'][:len(train)])\n",
        "S.fit(x_train,dataset['label'][:len(train)])\n",
        "N.fit(x_train,dataset['label'][:len(train)])\n",
        "Rf.fit(x_train, dataset['label'][:len(train)])\n",
        "ANN.fit(x_train, dataset['label'][:len(train)])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssBbFRAMAdw5"
      },
      "source": [
        "### Prediction of labels for Valid dataset using Count Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuCUGUVv8jtS"
      },
      "source": [
        "y_pred1= regressor.predict(x_valid)\n",
        "y_pred2= S.predict(x_valid)\n",
        "y_pred3= N.predict(x_valid)\n",
        "y_pred4= Rf.predict(x_valid)\n",
        "y_pred5= ANN.predict(x_valid)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoES5pH18yGh",
        "outputId": "17f5e527-16c8-4a99-e137-193c6565fb62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(5):\n",
        "  ac=accuracy_score(dataset['label'][len(train):], globals()['y_pred'+str(int(i+1))])\n",
        "  print(ac)\n",
        "  print(classification_report(dataset['label'][len(train):], globals()['y_pred'+str(int(i+1))]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9369158878504673\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.92      0.95      0.93      1020\n",
            "        real       0.95      0.93      0.94      1120\n",
            "\n",
            "    accuracy                           0.94      2140\n",
            "   macro avg       0.94      0.94      0.94      2140\n",
            "weighted avg       0.94      0.94      0.94      2140\n",
            "\n",
            "0.9210280373831776\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.90      0.94      0.92      1020\n",
            "        real       0.95      0.90      0.92      1120\n",
            "\n",
            "    accuracy                           0.92      2140\n",
            "   macro avg       0.92      0.92      0.92      2140\n",
            "weighted avg       0.92      0.92      0.92      2140\n",
            "\n",
            "0.9112149532710281\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.87      0.95      0.91      1020\n",
            "        real       0.95      0.87      0.91      1120\n",
            "\n",
            "    accuracy                           0.91      2140\n",
            "   macro avg       0.91      0.91      0.91      2140\n",
            "weighted avg       0.92      0.91      0.91      2140\n",
            "\n",
            "0.8663551401869158\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.84      0.88      0.86      1020\n",
            "        real       0.89      0.85      0.87      1120\n",
            "\n",
            "    accuracy                           0.87      2140\n",
            "   macro avg       0.87      0.87      0.87      2140\n",
            "weighted avg       0.87      0.87      0.87      2140\n",
            "\n",
            "0.7742990654205607\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.77      0.76      0.76      1020\n",
            "        real       0.78      0.79      0.79      1120\n",
            "\n",
            "    accuracy                           0.77      2140\n",
            "   macro avg       0.77      0.77      0.77      2140\n",
            "weighted avg       0.77      0.77      0.77      2140\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3mdqU5c9rJ8"
      },
      "source": [
        "## Tf-IDf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZtvoyW49iPd"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(dataset[0])\n",
        "X_train= X[:len(train)]\n",
        "X_valid= X[len(train):]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQIWZ7DV9vir",
        "outputId": "7e6d8275-1a85-4613-e276-8338f00d816d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "regressor.fit(X_train,dataset['label'][:len(train)])\n",
        "S.fit(X_train,dataset['label'][:len(train)])\n",
        "N.fit(X_train,dataset['label'][:len(train)])\n",
        "Rf.fit(X_train, dataset['label'][:len(train)])\n",
        "ANN.fit(X_train, dataset['label'][:len(train)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWxPs3Ds98N6"
      },
      "source": [
        "Y_pred1= regressor.predict(X_valid)\n",
        "Y_pred2= S.predict(X_valid)\n",
        "Y_pred3= N.predict(X_valid)\n",
        "Y_pred4= Rf.predict(X_valid)\n",
        "Y_pred5= ANN.predict(X_valid)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb9MuuTM-CoQ",
        "outputId": "7f09b7c9-d38a-4a70-c4d9-af0586b8d68b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(5):\n",
        "  ac=accuracy_score(dataset['label'][len(train):], globals()['Y_pred'+str(int(i+1))])\n",
        "  print(ac)\n",
        "  print(classification_report(dataset['label'][len(train):], globals()['Y_pred'+str(int(i+1))]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9257009345794392\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.91      0.94      0.92      1020\n",
            "        real       0.95      0.91      0.93      1120\n",
            "\n",
            "    accuracy                           0.93      2140\n",
            "   macro avg       0.93      0.93      0.93      2140\n",
            "weighted avg       0.93      0.93      0.93      2140\n",
            "\n",
            "0.9341121495327103\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.91      0.96      0.93      1020\n",
            "        real       0.96      0.91      0.94      1120\n",
            "\n",
            "    accuracy                           0.93      2140\n",
            "   macro avg       0.93      0.94      0.93      2140\n",
            "weighted avg       0.94      0.93      0.93      2140\n",
            "\n",
            "0.9112149532710281\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.87      0.95      0.91      1020\n",
            "        real       0.95      0.87      0.91      1120\n",
            "\n",
            "    accuracy                           0.91      2140\n",
            "   macro avg       0.91      0.91      0.91      2140\n",
            "weighted avg       0.92      0.91      0.91      2140\n",
            "\n",
            "0.8602803738317757\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.85      0.86      0.85      1020\n",
            "        real       0.87      0.86      0.87      1120\n",
            "\n",
            "    accuracy                           0.86      2140\n",
            "   macro avg       0.86      0.86      0.86      2140\n",
            "weighted avg       0.86      0.86      0.86      2140\n",
            "\n",
            "0.658411214953271\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.58      0.99      0.74      1020\n",
            "        real       0.99      0.35      0.52      1120\n",
            "\n",
            "    accuracy                           0.66      2140\n",
            "   macro avg       0.78      0.67      0.63      2140\n",
            "weighted avg       0.79      0.66      0.62      2140\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNdBpns-IPen"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}